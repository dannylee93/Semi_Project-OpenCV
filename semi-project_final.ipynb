{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자동차 번호판 검출하기\n",
    "- 자동차 번호판 부분만 검출해 따로 저장한 후, 이미지 검색기로 원본 사진(자동차) 서칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import PIL \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 이미지 불러올 경로 지정\n",
    "img_paths = glob.glob('data/img/*.jpg') # glob 함수로 폴더 내 모든 jpg 파일을 불러옴\n",
    "for img_path in img_paths: # img_paths에서 파일 경로 하나씩 꺼내오기\n",
    "    img = cv2.imread(img_path) # 해당 경로에 있는 jpg 이미지 불러오기\n",
    "    \n",
    "    height, width, channel = img.shape # 뒤에서 쓸 높이, 너비, 채널 변수 설정\n",
    "    \n",
    "    # 그레이스케일 적용\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # Thresholding 하기\n",
    "    blurred = cv2.GaussianBlur(gray, (3,3), 0) # 가우시안 블러링 \n",
    "    img_th = cv2.adaptiveThreshold(blurred,\n",
    "                              maxValue=255.0,\n",
    "                              adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                              thresholdType=cv2.THRESH_BINARY_INV,\n",
    "                              blockSize=19,\n",
    "                              C=9) \n",
    "\n",
    "    # 해당 이미지의 모든 Contour 검출\n",
    "    _, cnts, _=cv2.findContours(img_th, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "    \n",
    "    # Contour 그려주기\n",
    "    cv2.drawContours(result, contours=cnts, contourIdx=-1, color=(255, 0, 255))\n",
    "    result = np.zeros((height, width, channel), dtype=np.uint8) \n",
    "\n",
    "    cnts_dict = []\n",
    "\n",
    "    for cnt in cnts: # Contour 하나씩 꺼내기\n",
    "        x, y, w, h = cv2.boundingRect(cnt) # 컨투어에 외접한 직사각형 좌표(x, y), 높이, 너비 리턴\n",
    "        cv2.rectangle(result, pt1=(x, y), pt2=(x+w, y+h), color=(255, 0, 255), thickness=2)\n",
    "        # 해당 좌표를 따라 사각형 그리기\n",
    "\n",
    "        cnts_dict.append({\n",
    "            'contour':cnt,\n",
    "            'x':x,\n",
    "            'y':y,\n",
    "            'w':w,\n",
    "            'h':h,\n",
    "            'cx':x + (w/2),\n",
    "            'cy':y + (h/2)}) # 그려진 사각형들의 컨투어와 좌표를 cnts_dict에 추가\n",
    "\n",
    "    # 불필요한 contour 솎아내기\n",
    "    MIN_AREA = 80\n",
    "    MIN_WIDTH, MIN_HEIGHT = 2, 8\n",
    "    MIN_RATIO, MAX_RATI0 = 0.25, 1.0 # 최소, 최댓값 지정\n",
    "\n",
    "    possible_cnts = [] # 필요한 contour만 담을 그릇 만들기\n",
    "\n",
    "    cnt = 0\n",
    "    for d in cnts_dict:\n",
    "        area = d['w']*d['h'] # contour 사각형 넓이\n",
    "        ratio = d['w']/d['h'] # contour 사각형 너비/높이 비율\n",
    "\n",
    "        if area > MIN_AREA \\\n",
    "        and d['w'] > MIN_WIDTH and d['h'] > MIN_HEIGHT \\\n",
    "        and MIN_RATIO < ratio < MAX_RATI0:\n",
    "            d['idx'] = cnt\n",
    "            cnt += 1\n",
    "            possible_cnts.append(d) # 조건에 맞는 Contour만 저장해주기\n",
    "\n",
    "    result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "    for d in possible_cnts:\n",
    "        cv2.rectangle(result, \n",
    "                      pt1=(d['x'], d['y']), \n",
    "                      pt2=(d['x']+d['w'], d['y']+d['h']),\n",
    "                      color=(255, 0 , 255),\n",
    "                      thickness=2) # 조건에 맞는 Contour 사각형만 그려 표시하기\n",
    "    \n",
    "    # 차량 번호판 contour만 검출하기 위한 기준값들 지정\n",
    "    MAX_DIAG_MULTIPLYER = 5\n",
    "    MAX_ANGLE_DIFF = 12.0\n",
    "    MAX_AREA_DIFF = 0.5\n",
    "    MAX_WIDTH_DIFF = 0.8\n",
    "    MAX_HEIGHT_DIFF = 0.2\n",
    "    MIN_N_MATCHED = 3\n",
    "\n",
    "    def find_chars(cnt_list):\n",
    "        matched_result_idx = [] # 최종 매칭 Contour들을 담을 그릇\n",
    "\n",
    "        for d1 in cnt_list:\n",
    "            matched_cnts_idx = [] # 매칭되는 Contour들의 index를 담을 그릇\n",
    "            for d2 in cnt_list:\n",
    "                if d1['idx'] == d2['idx']:\n",
    "                    continue\n",
    "\n",
    "                dx = abs(d1['cx'] - d2['cx'])\n",
    "                dy = abs(d1['cy'] - d2['cy']) # 각 Contour들의 거리 구하기\n",
    "\n",
    "                diagonal_length1 = np.sqrt(d1['w']**2 + d1['h']**2) # Contour 사각형 대각선 길이 구하기, 피타고라스 정리 활용 \n",
    "                distance = np.linalg.norm(np.array([d1['cx'], d1['cy']]) - np.array([d2['cx'], d2['cy']]))\n",
    "                \n",
    "                if dx == 0:\n",
    "                    angle_diff = 90\n",
    "                else:\n",
    "                    angle_diff = np.degrees(np.arctan(dy/dx)) # 이미지 기울어졌을 경우 각도 계산해주기\n",
    "\n",
    "                area_diff = abs(d1['w']*d1['h'] - d2['w']*d2['h']) / (d1['w']*d1['h'])\n",
    "                width_diff = abs(d1['w'] - d2['w']) / d1['w']\n",
    "                height_diff = abs(d1['h'] - d2['h']) / d1['h']\n",
    "\n",
    "                if distance < diagonal_length1 * MAX_DIAG_MULTIPLYER \\\n",
    "                and angle_diff < MAX_ANGLE_DIFF and area_diff < MAX_AREA_DIFF \\\n",
    "                and width_diff < MAX_WIDTH_DIFF and height_diff < MAX_HEIGHT_DIFF:\n",
    "                    matched_cnts_idx.append(d2['idx']) # 조건에 맞는 Contour들의 idx만 추가해주기 \n",
    "\n",
    "            matched_cnts_idx.append(d1['idx'])\n",
    "\n",
    "            if len(matched_cnts_idx) < MIN_N_MATCHED:\n",
    "                continue\n",
    "\n",
    "            matched_result_idx.append(matched_cnts_idx)\n",
    "\n",
    "            unmatched_cnt_idx = [] # 매칭되지 않는 Contour 그릇 만들기\n",
    "            for d4 in cnt_list:\n",
    "                if d4['idx'] not in matched_cnts_idx:\n",
    "                    unmatched_cnt_idx.append(d4['idx'])\n",
    "\n",
    "            unmatched_cnt = np.take(possible_cnts, unmatched_cnt_idx)\n",
    "\n",
    "            recursive_cnt_list = find_chars(unmatched_cnt)\n",
    "\n",
    "            for idx in recursive_cnt_list:\n",
    "                matched_result_idx.append(idx)\n",
    "\n",
    "            break\n",
    "\n",
    "        return matched_result_idx # 최종 매칭 Contour Index 돌려주기\n",
    "\n",
    "    result_idx = find_chars(possible_cnts)\n",
    "\n",
    "    matched_result = []\n",
    "    for idx_list in result_idx:\n",
    "        matched_result.append(np.take(possible_cnts, idx_list))\n",
    "\n",
    "    result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "    for r in matched_result:\n",
    "        for d in r:\n",
    "            cv2.rectangle(result, \n",
    "                          pt1=(d['x'], d['y']), \n",
    "                          pt2=(d['x']+d['w'], d['y']+d['h']), \n",
    "                          color=(255, 0, 255),\n",
    "                         thickness=2) # 최종 매칭된 Contour들에 사각형 그리기\n",
    "\n",
    "    # 기준값 지정하기\n",
    "    PLATE_WIDTH_PADDING = 1.3\n",
    "    PLATE_HEIGHT_PADDING = 1.5\n",
    "    MIN_PLATE_RATIO = 3\n",
    "    MAX_PLATE_RATIO = 10\n",
    "\n",
    "    plate_imgs = []\n",
    "    plate_infos = []\n",
    "\n",
    "    for i, matched_chars in enumerate(matched_result):\n",
    "        sorted_chars = sorted(matched_chars, key=lambda x:x['cx']) \n",
    "\n",
    "        plate_cx = (sorted_chars[0]['cx'] + sorted_chars[-1]['cx']) / 2 # 중간점 x좌표 지정\n",
    "        plate_cy = (sorted_chars[0]['cy'] + sorted_chars[-1]['cy']) / 2 # 중간점 y좌표 지정\n",
    "\n",
    "        plate_width = (sorted_chars[-1]['x'] + sorted_chars[-1]['w'] - sorted_chars[0]['x'])*PLATE_WIDTH_PADDING \n",
    "        # 검출할 부분의 너비 구하기\n",
    "\n",
    "        sum_height = 0\n",
    "        for d in sorted_chars:\n",
    "            sum_height += d['h']\n",
    "\n",
    "        plate_height = int(sum_height / len(sorted_chars)*PLATE_HEIGHT_PADDING) # 검출할 지점 높이 구하기\n",
    "\n",
    "        triangle_height = sorted_chars[-1]['cy'] - sorted_chars[0]['cy']\n",
    "        triangle_hypotenus = np.linalg.norm(np.array([sorted_chars[0]['cx'], sorted_chars[0]['cy']]) - \n",
    "                                           np.array([sorted_chars[-1]['cx'], sorted_chars[-1]['cy']]))\n",
    "\n",
    "        angle = np.degrees(np.arcsin(triangle_height / triangle_hypotenus)) # 이동할 각도 구하기\n",
    "\n",
    "        rotation_mtrx = cv2.getRotationMatrix2D(center=(plate_cx, plate_cy), angle=angle, scale=1.0) \n",
    "        img_rotated = cv2.warpAffine(img_th, M=rotation_mtrx, dsize=(width, height)) # 원근 변환 \n",
    "        \n",
    "        # 번호판 이미지 검출\n",
    "        img_cropped = cv2.getRectSubPix(img_rotated,\n",
    "                                       patchSize = (int(plate_width), int(plate_height)), \n",
    "                                       center=(int(plate_cx), int(plate_cy))) # img_rotated 대신 img를 넣을 경우 컬러로 검출됨\n",
    "\n",
    "        if img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO \\\n",
    "        or img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO > MAX_PLATE_RATIO:\n",
    "            continue\n",
    "\n",
    "        plate_imgs.append(img_cropped)\n",
    "        plate_infos.append({\n",
    "            'x':int(plate_cx - plate_width / 2),\n",
    "            'y':int(plate_cy - plate_height / 2),\n",
    "            'w':int(plate_width),\n",
    "            'h':int(plate_height)})\n",
    "        \n",
    "        now = datetime.datetime.now()\n",
    "        now_str = now.strftime(\"%H.%M.%S.%f\")\n",
    "        finished = Image.fromarray(img_cropped) # numpy array 자료형을 image 객체로 변환해준다\n",
    "        finished.save(\"data/n/{}.jpg\".format(now_str)) # 지정한 폴더에 저장하기\n",
    "        # 컬러 이미지는 data/num2에 따로 저장      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전처리한 이미지\n",
    "***\n",
    "![result](https://user-images.githubusercontent.com/58945760/72497450-e2740100-386f-11ea-8482-18bae7104d13.png)\n",
    "\n",
    "\n",
    "- 컬러 이미지\n",
    "***\n",
    "![num2](https://user-images.githubusercontent.com/58945760/72580186-959b3380-391e-11ea-99ba-d11f4d77ea92.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 이미지 검색기 만들기(1차)\n",
    "\n",
    "- Searching이 진행되긴 하나 추출기가 번호판과 차량 이미지 사이에 매칭점을 찾지 못해 error가 발생한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, cv2, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검출한 번호판 이미지로 검색기 돌려보기\n",
    "detector = cv2.ORB_create()\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params = {'algorithm' : FLANN_INDEX_LSH, 'table_number' : 6, 'key_size' : 12, 'multi_probe_level' : 1}\n",
    "search_params = {'checks': 32}\n",
    "matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "def serch(img):\n",
    "    kp1, desc1 = detector.detectAndCompute(img, None)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    img_paths = glob.glob('data/img/*.jpg')\n",
    "    for img_path in img_paths:\n",
    "        cars = cv2.imread(img_path)\n",
    "        cv2.imshow('searching..', cars)\n",
    "        cv2.waitKey(10)\n",
    "\n",
    "        gray2 = cv2.cvtColor(cars, cv2.COLOR_BGR2GRAY)\n",
    "        kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "        matches = matcher.knnMatch(desc1, desc2, 2)\n",
    "        \n",
    "        ratio = 0.7\n",
    "        good_matches = [m[0] for m in matches if len(m) == 2 and m[0].distance < m[1].distance*ratio] \n",
    "        \n",
    "        MIN_MATCH = 10\n",
    "        if len(good_matches) > MIN_MATCH:\n",
    "            src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches])\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches])\n",
    "            mtrx, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "            accuracy = float(mask.sum()) / mask.size\n",
    "\n",
    "            results[img_path] = accuracy\n",
    " #       cv2.destroyAllWindows('serching..')\n",
    "\n",
    "    if len(results) > 0 :\n",
    "        results = sorted([(v, k) for (k, v) in results.items() if v>0], reverse=True)\n",
    "\n",
    "        return results\n",
    "\n",
    "img_test = cv2.imread('data/num2/17.57.40.996459.jpg') # 번호판 이미지를 넣을 때 매칭이 안되는 오류 발생\n",
    "gray = cv2.cvtColor(img_test, cv2.COLOR_BGR2GRAY)\n",
    "results = serch(gray)\n",
    "\n",
    "\n",
    "if type(results) is None :\n",
    "    print(\"NO matched cars found\")\n",
    "else:\n",
    "    for(i, (accuracy, img_path)) in enumerate(results):\n",
    "        print(i, img_path, accuracy)\n",
    "        if i == 0:\n",
    "            cars = cv2.imread(img_path)\n",
    "            cv2.putText(cars, (\"Accuracy:%.2f%%\"%(accuracy*100)), (10,100),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.imshow('result', cars)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 매칭점 확인으로 적합한 추출기 선정\n",
    "- 강의에서 배웠던 추출기들을 활용하여 번호판 이미지와 매칭점을 찾아낼 수 있는 추출기를 찾는다.  \n",
    "\n",
    "### 1. BF + ORB(실패)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BFMatcher 000001E9D9DBEB70>\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\batch_distance.cpp:238: error: (-215:Assertion failed) type == src2.type() && src1.cols == src2.cols && (type == 5 || type == 0) in function 'cv::batchDistance'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-377e294fd02b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# 매칭 계산 ---④\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;31m# 매칭 결과 그리기 ---⑤\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m res = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\batch_distance.cpp:238: error: (-215:Assertion failed) type == src2.type() && src1.cols == src2.cols && (type == 5 || type == 0) in function 'cv::batchDistance'\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('data/img/car_plate10.jpg')\n",
    "img2 = cv2.imread('data/num2/17.57.40.996459.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ORB 서술자 추출기 생성 ---①\n",
    "detector = cv2.ORB_create()\n",
    "# 각 영상에 대해 키 포인트와 서술자 추출 ---②\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "\n",
    "# BFMatcher 생성, Hamming 거리, 상호 체크 ---③\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "print(matcher)\n",
    "\n",
    "# 매칭 계산 ---④\n",
    "matches = matcher.match(desc1, desc2)\n",
    "# 매칭 결과 그리기 ---⑤\n",
    "res = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "                     flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "cv2.imshow('BFMatcher + ORB', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BF + SIFT (실패)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) c:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'cv::CvtHelper<struct cv::Set<3,4,-1>,struct cv::Set<1,-1,-1>,struct cv::Set<0,2,5>,2>::CvtHelper'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-0a74ee1e2095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgray1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgray2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m## SIFT 서술자 추출기 생성 ---①\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) c:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'cv::CvtHelper<struct cv::Set<3,4,-1>,struct cv::Set<1,-1,-1>,struct cv::Set<0,2,5>,2>::CvtHelper'\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('data/img/car_plate10.jpg')\n",
    "img2 = cv2.imread('data/num2/17.57.40.996459.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## SIFT 서술자 추출기 생성 ---①\n",
    "detector = cv2.xfeatures2d.SIFT_create()\n",
    "# 각 영상에 대해 키 포인트와 서술자 추출 ---②\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "\n",
    "# BFMatcher 생성, L1 거리, 상호 체크 ---③\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "# 매칭 계산 ---④\n",
    "matches = matcher.match(desc1, desc2)\n",
    "# 매칭 결과 그리기 ---⑤\n",
    "res = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "                      flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "# 결과 출력 \n",
    "cv2.imshow('BFMatcher + SIFT', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BF + SURF(성공)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread('data/img/car_plate100.jpg')\n",
    "img2 = cv2.imread('data/num/13.43.55.925497.jpg')\n",
    "img3 = cv2.imread('data/num2/17.57.41.032328.jpg')\n",
    "\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "gray3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# SURF 서술자 추출기 생성 ---①\n",
    "detector = cv2.xfeatures2d.SURF_create()\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "kp3, desc3 = detector.detectAndCompute(gray3, None)\n",
    "\n",
    "# BFMatcher 생성, L2 거리, 상호 체크 ---③\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "\n",
    "# 매칭 계산 ---④\n",
    "matches = matcher.match(desc1, desc2)\n",
    "# 매칭 결과 그리기 ---⑤\n",
    "res1 = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "                     flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "cv2.imshow('BF + SURF1', res1) # 전처리한 이미지 매칭\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# 매칭 계산 ---④\n",
    "matches = matcher.match(desc1, desc3)\n",
    "# 매칭 결과 그리기 ---⑤\n",
    "res2 = cv2.drawMatches(img1, kp1, img3, kp3, matches, None, \\\n",
    "                     flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "cv2.imshow('BF + SURF2', res2) # 컬러 이미지 매칭\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전처리한 이미지 매칭점\n",
    "![match](https://user-images.githubusercontent.com/58945760/72691461-ef8f3980-3b68-11ea-905f-cd9aae407317.PNG)\n",
    "\n",
    "- 컬러 이미지 매칭점\n",
    "![match2](https://user-images.githubusercontent.com/58945760/72691488-2c5b3080-3b69-11ea-8476-3bd122834bd2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. FLANN + SURF(실패)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('data/img/car_plate100.jpg')\n",
    "img2 = cv2.imread('data/num2/17.57.41.032328.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# SURF 생성\n",
    "detector = cv2.xfeatures2d.SURF_create()\n",
    "# 키 포인트와 서술자 추출\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "\n",
    "# 인덱스 파라미터와 검색 파라미터 설정 ---①\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "# Flann 매처 생성 ---③\n",
    "matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "# 매칭 계산 ---④\n",
    "matches = matcher.match(desc1, desc2)\n",
    "# 매칭 그리기\n",
    "res = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "                flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "cv2.imshow('Flann + SURF', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![match3](https://user-images.githubusercontent.com/58945760/72691526-704e3580-3b69-11ea-9d3c-8bc34878f5ae.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 검색기 만들기(2차)\n",
    "- 원래 코드에 쓰였던 ORB+KNN+FLANN 추출기를 SURF+BF 추출기로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검출한 번호판 이미지로 검색기 돌려보기\n",
    "\n",
    "detector = cv2.xfeatures2d.SURF_create()\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "\n",
    "def serch(img):\n",
    "#     gray1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    img_paths = glob.glob('data/img/*.jpg')\n",
    "    for img_path in img_paths:\n",
    "        cars = cv2.imread(img_path)\n",
    "        cv2.imshow('searching..', cars)\n",
    "        cv2.waitKey(5)\n",
    "\n",
    "        gray2 = cv2.cvtColor(cars, cv2.COLOR_BGR2GRAY)\n",
    "        kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "        matches = matcher.match(desc1, desc2)\n",
    "\n",
    "        # 매칭 결과를 거리기준 오름차순으로 정렬 ---③\n",
    "        matches = sorted(matches, key=lambda x:x.distance)\n",
    "\n",
    "        # 최소 거리 값과 최대 거리 값 확보 ---④\n",
    "        min_dist, max_dist = matches[0].distance, matches[-1].distance\n",
    "        # 최소 거리의 20% 지점을 임계점으로 설정 ---⑤\n",
    "        ratio = 0.2\n",
    "        good_thresh = (max_dist - min_dist) * ratio + min_dist\n",
    "\n",
    "        # 임계점 보다 작은 매칭점만 좋은 매칭점으로 분류 ---⑥\n",
    "        #m.distance 매칭객체의 거리 공통함수부분참조  \n",
    "        good_matches = [m for m in matches if m.distance < good_thresh]\n",
    "        \n",
    "        MIN_MATCH = 10\n",
    "        if len(good_matches) > MIN_MATCH:\n",
    "            src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches])\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches])\n",
    "            mtrx, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "            accuracy = float(mask.sum()) / mask.size\n",
    "\n",
    "            results[img_path] = accuracy\n",
    " #       cv2.destroyAllWindows('serching..')\n",
    "\n",
    "    if len(results) > 0 :\n",
    "        results = sorted([(v, k) for (k, v) in results.items() if v > 0], reverse=True)\n",
    "\n",
    "        return results\n",
    "\n",
    "img_test = cv2.imread('data/num2/17.57.40.996459.jpg') \n",
    "gray = cv2.cvtColor(img_test, cv2.COLOR_BGR2GRAY)\n",
    "results = serch(gray)\n",
    "\n",
    "\n",
    "if type(results) is None :\n",
    "    print(\"NO matched cars found\")\n",
    "else:\n",
    "    for(i, (accuracy, img_path)) in enumerate(results):\n",
    "#         print(i, img_path, accuracy)\n",
    "        if i == 0:\n",
    "            cars = cv2.imread(img_path)\n",
    "            cv2.putText(cars, (\"Accuracy:%.2f%%\"%(accuracy*100)), (10,100),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('number', img_test)              \n",
    "cv2.imshow('result', cars)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 검색기 만들기(3차)\n",
    "- Good matches를 뽑아내지 않고 전체 matches만으로 이미지 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검출한 번호판 이미지로 검색기 돌려보기((Good match 사용하지 않음)\n",
    "\n",
    "detector = cv2.xfeatures2d.SURF_create()\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "\n",
    "def serch(img):\n",
    "    kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    img_paths = glob.glob('data/img/*.jpg')\n",
    "    for img_path in img_paths:\n",
    "        cars = cv2.imread(img_path)\n",
    "        cv2.imshow('searching..', cars)\n",
    "        cv2.waitKey(3)\n",
    "\n",
    "        gray2 = cv2.cvtColor(cars, cv2.COLOR_BGR2GRAY)\n",
    "        kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "        matches = matcher.match(desc1, desc2)\n",
    "        \n",
    "        MIN_MATCH = 10\n",
    "        if len(matches) > MIN_MATCH:\n",
    "            src_pts = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "            mtrx, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "            accuracy = float(mask.sum()) / mask.size\n",
    "\n",
    "            results[img_path] = accuracy\n",
    " #       cv2.destroyAllWindows('serching..')\n",
    "\n",
    "    if len(results) > 0 :\n",
    "        results = sorted([(v, k) for (k, v) in results.items() if v > 0], reverse=True)\n",
    "\n",
    "        return results\n",
    "\n",
    "img_test = cv2.imread('data/num2/17.57.41.032328.jpg') \n",
    "gray = cv2.cvtColor(img_test, cv2.COLOR_BGR2GRAY)\n",
    "results = serch(gray)\n",
    "\n",
    "\n",
    "if type(results) is None :\n",
    "    print(\"NO matched cars found\")\n",
    "else:\n",
    "    for(i, (accuracy, img_path)) in enumerate(results):\n",
    "#         print(i, img_path, '%.2f'%accuracy)\n",
    "        if i == 0:\n",
    "            cars = cv2.imread(img_path)\n",
    "            cv2.putText(cars, (\"Accuracy:%.2f%%\"%(accuracy*100)), (10,100),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('number', img_test)            \n",
    "cv2.imshow('result', cars)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![match4](https://user-images.githubusercontent.com/58945760/72691519-5f9dbf80-3b69-11ea-8b46-e659ca432108.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Extra)Tesseract로 글자 인식해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import PIL\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'\n",
    "\n",
    "print()\n",
    "img_list = []\n",
    "number_list = []\n",
    "error_list = []\n",
    "\n",
    "img_paths = glob.glob('data/num/*.jpg') # glob 함수로 폴더 내 모든 jpg 파일을 불러옴\n",
    "for img_path in img_paths: # img_paths에서 파일 경로 하나씩 꺼내오기\n",
    "    img = cv2.imread(img_path)\n",
    "    img_list.append(img)\n",
    "    number = pytesseract.image_to_string(img, lang = 'eng')\n",
    "    \n",
    "    if number == '':\n",
    "#         print('차량 번호 인식에 실패했습니다.')\n",
    "        error_list.append(number)\n",
    "    \n",
    "    else:\n",
    "#         print('차량 번호:', number)\n",
    "        number_list.append(number)\n",
    "        \n",
    "    result = len(number_list) / len(img_list)\n",
    "print()    \n",
    "print('차량 번호 검출율:', '%.2f'%result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고 페이지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://kolikim.tistory.com/44\n",
    "# https://stackoverflow.com/questions/902761/saving-a-numpy-array-as-an-image/19174800\n",
    "# https://github.com/kairess/license_plate_recognition/blob/master/main.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
